---
title: 7.1 Randomization Inference
subtitle: PLSC30500, Fall 2021
author: 
  - co-taught by Molly Offer-Westort & Andy Eggers
  # - .small-text[(This lecture with references to Gerber & Green 2012)]
output: 
  xaringan::moon_reader:
    self_contained: true
    css: [default, uchicago_pol_meth.css]
    nature:
      highlightLines: true
      countIncrementalSlides: no
---
exclude: true
# Estimation

---


```{r setup, include=FALSE}
library(tidyverse)
set.seed(60637)
options(width = 60)
```

```{css, echo=FALSE}
.small-output .remark-code{
  font-size: small;
}

.white { color: white; }
.red { color: red; }
.blue { color: blue; }

# .show-only-last-code-result pre + pre:not(:last-of-type) code[class="remark-code"] {
#     display: none;
# }
```

## Randomization inference

Gerber & Green example adapted from: 

Chattopadhyay, R., & Duflo, E. (2004). Women as policy makers: Evidence from a randomized policy experiment in India. *Econometrica*, 72(5), 1409-1443.

---



(Augmented) Gerber Green example:

- Population: 7 villages
- Treatment: $D= 1$ if female-headed council, $D=0$ if male
- Outcome: Budget allocation to sanitation


What we see:


|           | $Y_i(0)$ | $Y_i(1)$ | $D_i$ | $Y_i$ |
|-----------|----------|----------|-------|----------|
| Village 1 | .red[?]        | 15       | 1     | 15       |
| Village 2 | 15       | .red[?]        | 0     | 15       |
| Village 3 | 20       | .red[?]        | 0     | 20       |
| Village 4 | 20       | .red[?]        | 0     | 20       |
| Village 5 | 10       | .red[?]        | 0     | 10       |
| Village 6 | 15       | .red[?]        | 0     | 15       |
| Village 7 | .red[?]        | 30       | 1     | 30       |
| .white[**Average**]| .white[**15**] |   .white[**22.14**]  |  |  |



---



We used the difference in means estimator previously to get an estimate of the average treatment effect over this population of 7 villages, $\textrm{E}[\tau_i]$. 

--

|           | $Y_i(0)$ | $Y_i(1)$ | $D_i$ | $Y_i$ |
|-----------|----------|----------|-------|----------|
| Village 1 | .red[?]        | 15       | 1     | 15       |
| Village 2 | 15       | .red[?]        | 0     | 15       |
| Village 3 | 20       | .red[?]        | 0     | 20       |
| Village 4 | 20       | .red[?]        | 0     | 20       |
| Village 5 | 10       | .red[?]        | 0     | 10       |
| Village 6 | 15       | .red[?]        | 0     | 15       |
| Village 7 | .red[?]        | 30       | 1     | 30       |
| **Average**| **15** |   **22.14**  |  |  |

$$
\hat\tau_{DM} = \frac{\sum_i^n Y_i D_i}{\sum_i^n D_i} - \frac{\sum_i^n Y_i (1-D_i)}{\sum_i^n (1-D_i)}
$$
--

$$
= 22.14-15 = 7.14
$$

---

- But what can we say about our uncertainty about this estimate? The number of observations in each group is pretty small. 

--

- Is the estimate meaningfully different from zero?

--

- How likely would we be to see an effect this size just by chance?


---

One way to think about this is to assume the ITE for all individuals is exactly zero. Then, no matter how we randomized treatment assignment, we would see the same $Y_i$s. 

--

We can then say how often we would see a treatment effect of this size just by chance, under the assumption that individual treatment effects were actually zero. 

---

Assuming all treatment effects are exactly zero is called the **sharp null hypothesis of no effect**. 

--

We might write it this way:

$$
H_0: \tau_i = 0, \text{ for all } i \text{ in our pop.}
$$


---
Then we can fill in this table $\dots$

|           | $Y_i(0)$ | $Y_i(1)$ | $D_i$ | $Y_i$ | $\tau_i^0$ |
|-----------|----------|----------|-------|-------|------------|
| Village 1 | .red[?]  | 15       | 1     | 15    | .red[?]    |
| Village 2 | 15       | .red[?]  | 0     | 15    | .red[?]    |
| Village 3 | 20       | .red[?]  | 0     | 20    | .red[?]    |
| Village 4 | 20       | .red[?]  | 0     | 20    | .red[?]    |
| Village 5 | 10       | .red[?]  | 0     | 10    | .red[?]    |
| Village 6 | 15       | .red[?]  | 0     | 15    | .red[?]    |
| Village 7 | .red[?]  | 30       | 1     | 30    | .red[?]    |



---
$\dots$ as this:

|             | $Y_i(0)$ | $Y_i(1)$  | $D_i$ | $Y_i$ | $\tau_i^0$ |
|-------------|----------|-----------|-------|-------|------------|
| Village 1   | .red[15] | 15        | 1     | 15    | .red[0]    |
| Village 2   | 15       | .red[15]  | 0     | 15    | .red[0]    |
| Village 3   | 20       | .red[20]  | 0     | 20    | .red[0]    |
| Village 4   | 20       | .red[20]  | 0     | 20    | .red[0]    |
| Village 5   | 10       | .red[10]  | 0     | 10    | .red[0]    |
| Village 6   | 15       | .red[15]  | 0     | 15    | .red[0]    |
| Village 7   | .red[30] | 30        | 1     | 30    | .red[0]    |



---
We can re-run the randomization, and the potential outcomes and observed $Y_i$ will not change, but the treatment effect estimate will. 

|             | $Y_i(0)$ | $Y_i(1)$  | $D_i$    | $Y_i$ | $\tau_i^0$ |
|-------------|----------|-----------|----------|-------|------------|
| Village 1   | .red[15] | 15        | .blue[0] | 15    | .red[0]    |
| Village 2   | 15       | .red[15]  | .blue[1] | 15    | .red[0]    |
| Village 3   | 20       | .red[20]  | .blue[0] | 20    | .red[0]    |
| Village 4   | 20       | .red[20]  | .blue[0] | 20    | .red[0]    |
| Village 5   | 10       | .red[10]  | .blue[0] | 10    | .red[0]    |
| Village 6   | 15       | .red[15]  | .blue[1] | 15    | .red[0]    |
| Village 7   | .red[30] | 30        | .blue[0] | 30    | .red[0]    |
--


$\frac{\sum_i^n Y_i D_i}{\sum_i^n D_i} = \color{blue}{15}$

$\frac{\sum_i^n Y_i (1-D_i)}{\sum_i^n (1-D_i)} = \color{blue}{18.33}$

$$
\hat{\tau}_{DM} = \color{blue}{-3.33}
$$

---
We can re-run the randomization, and the potential outcomes and observed $Y_i$ will not change, but the treatment effect estimate will. 

|             | $Y_i(0)$ | $Y_i(1)$  | $D_i$    | $Y_i$ | $\tau_i^0$ |
|-------------|----------|-----------|----------|-------|------------|
| Village 1   | .red[15] | 15        | .blue[0] | 15    | .red[0]    |
| Village 2   | 15       | .red[15]  | .blue[0] | 15    | .red[0]    |
| Village 3   | 20       | .red[20]  | .blue[1] | 20    | .red[0]    |
| Village 4   | 20       | .red[20]  | .blue[0] | 20    | .red[0]    |
| Village 5   | 10       | .red[10]  | .blue[0] | 10    | .red[0]    |
| Village 6   | 15       | .red[15]  | .blue[0] | 15    | .red[0]    |
| Village 7   | .red[30] | 30        | .blue[1] | 30    | .red[0]    |



$\frac{\sum_i^n Y_i D_i}{\sum_i^n D_i} = \color{blue}{25}$

$\frac{\sum_i^n Y_i (1-D_i)}{\sum_i^n (1-D_i)} = \color{blue}{15}$

$$
\hat{\tau}_{DM} = \color{blue}{10}
$$

---
We can re-run the randomization, and the potential outcomes and observed $Y_i$ will not change, but the treatment effect estimate will. 

|             | $Y_i(0)$ | $Y_i(1)$  | $D_i$    | $Y_i$ | $\tau_i^0$ |
|-------------|----------|-----------|----------|-------|------------|
| Village 1   | .red[15] | 15        | .blue[0] | 15    | .red[0]    |
| Village 2   | 15       | .red[15]  | .blue[0] | 15    | .red[0]    |
| Village 3   | 20       | .red[20]  | .blue[1] | 20    | .red[0]    |
| Village 4   | 20       | .red[20]  | .blue[1] | 20    | .red[0]    |
| Village 5   | 10       | .red[10]  | .blue[0] | 10    | .red[0]    |
| Village 6   | 15       | .red[15]  | .blue[0] | 15    | .red[0]    |
| Village 7   | .red[30] | 30        | .blue[0] | 30    | .red[0]    |



$\frac{\sum_i^n Y_i D_i}{\sum_i^n D_i} = \color{blue}{20}$

$\frac{\sum_i^n Y_i (1-D_i)}{\sum_i^n (1-D_i)} = \color{blue}{17}$

$$
\hat{\tau}_{DM} = \color{blue}{3}
$$

---
Because we know how treatment was assigned, we know all the possible ways treatment could be assigned across the villages, and the exact probability. 

--

There are seven villages, and we'll say that exactly two will get treatment. Each village is assigned treatment with equal probability. 

---

We can use the package `ri` to find the *exact* distribution of $\hat\tau_{DM}$ under the sharp null.

--

Our real data:

```{r}
library(ri)

df <- tibble(
  # our initial treatment vector
  D = c(1, 0, 0, 0, 0, 0, 1),
  # our initial response vector
  Y = c(15, 15, 20, 20, 10, 15, 30),
  # treatment assignment probability
  probs = rep(2/7, 7)
)

df
```


---

And our average treatment effect estimate under the real data:

```{r}
Y1 <- filter(df, D == 1) %>% pull(Y)
Y0 <- filter(df, D == 0) %>% pull(Y)

(dm_hat <- mean(Y1) - mean(Y0))
```


---

Adding in the hypothetical data

```{r}

df <- df %>% 
  bind_cols(
    # Y(0) under the sharp null of no effect
    Y0 = df$Y,
    # Y(1) under the sharp null of no effect
    Y1 = df$Y)

df
```


---

Consider all the ways treatment could be assigned:

```{r}
(perms <- genperms(df$D))
```

---
Then generate the sampling distribution of the ATE under the sharp null of no effect. 

```{r}

Ys_null <- list(
  Y0 = df$Y0,
  Y1 = df$Y1
)

dm <- gendist(Ys_null,
                   perms, 
                   prob=df$probs)
dm

null_dist <- tibble(dm)

```


---

The mean under our null distribution is exactly zero. Why?

```{r}
mean(null_dist$dm)
```


---

```{r, fig.height=4, fig.width = 5, fig.align = "center", echo=FALSE}

gg_bins <- null_dist %>% 
  group_by(dm) %>% 
  count() %>% 
  mutate(col = abs(dm) >= dm_hat)

ggplot(gg_bins, aes(x = dm, y = n)) +
  geom_col() +
  geom_vline(xintercept = 0, color = 'red')

```

--

```{r}
prop.table(table(null_dist))
```

--

```{r}
(pval <- mean(abs(null_dist) >= dm_hat))
```

---
```{r, fig.height=4, fig.width = 5, fig.align = "center", echo=FALSE}
ggplot(gg_bins, aes(x = dm, y = n, fill = col)) +
  geom_col() +
  geom_vline(xintercept = 0, color = 'red') + 
  scale_fill_manual(values=c("grey35", "#619CFF")) +
  theme(legend.position = 'none')
```


```{r}
(pval <- mean(abs(null_dist) >= dm_hat))
```

--

Under the null distribution, if we were to re-randomize the experiment many times, we would see a value *at least as extreme as our estimate* `r round(pval*100,2)`% of the time. 
--

That doesn't seem **that** unlikely--more than one in three times, we would see an estimate as large as we got, just by chance. 

---

`ri` produces the same exact p-value. 

```{r}

dispdist(distout = dm, 
         ate = dm_hat, 
         display.plot = FALSE)$two.tailed.p.value.abs
```


---

## Hypotheses


We framed our null hypothesis as below:

$$
H_0: \tau_i = 0, \text{ for all } i \text{ in our pop.}
$$

--

Implicitly, the alternative is that for some individual(s), the treatment effect is non-zero. 

$$
H_A: \tau_i \neq 0, \text{ for some } i \text{ in our pop.}
$$

--

In our case, we did not find strong evidence to reject the null hypothesis, i.e., our data is consistent with what we would see if the null hypothesis were true.

--

Note that we do NOT say that we reject or accept the alternative hypothesis. 

--

We can only say that our results were not consistent with or were consistent with what we would have seen under the null--i.e., we have evidence to reject or fail to reject the null. 


---
## Test statistics

Our difference in means estimator is a *statistic*. Statistics are functions of the data we observe.
--


$$
T_n = h(X_1, \dots, X_n)
$$

--

This should look a lot like our definiton of *estimators*. Estimators are a class of statistics that we use to approximate specific estimands.

--

*Test statistics* are the specific statistics we use to test a hypothesis. 

--

Here, our hypothesis was about the *individual treatment effect*. 



---

## Sampling Distributions

Our difference in means estimator is a function of the data we observe. 

--

Because there is randomness in the data, here, due to random assignment of treatment, the estimator is also a random variable. 

--

Just like other random variables have distributions to describe them, estimators also have distributions. 

--

We don't know the *true* distribution of the difference in means estimator, for the same reason that we don't know individual treatment effects.

--
.red[(FPoCI!)]

--

But we DO know what the distribution would be under the null. 


---

How do we determine what the null is?

--

We formalize our hypotheses in terms of the effect we are trying to find in the data. Is there a treatment effect? Is there a difference between these two groups?

--

The null is the case when there is no effect, or no difference. 


---


# Analyzing an experiment


Considering some real data, we'll look at

Butler, D. M., & Broockman, D. E. (2011). *Do politicians racially discriminate against constituents? A field experiment on state legislators.* AJPS. 

--

Data is available at the Yale ISPS data archive: [isps.yale.edu/research/data](isps.yale.edu/research/data)

---

```{r, message=FALSE}

file <- '../data/legislators_email/Butler_Broockman_AJPS_2011_public_csv.csv'
df <- read_csv(file)

```


```{r, echo = FALSE}
df
```

---

Recall that treatment is 1 if the sender was DeShawn Jackson, and 0 if Jake Mueller. 

```{r}
table(df$treat_deshawn)
```

--

The primary outcome is whether legislators replied at all. 

```{r}
table(df$reply_atall)
```

---

We're going to manipulate our data so it takes the format $Y$ ~ $D$. 


```{r}
df <- df %>% 
  mutate(D = treat_deshawn,
         Y = reply_atall)
```

--

To get the difference-in-means estimate of the ATE, 

```{r}
Y1 <- filter(df, D == 1) %>% pull(Y)
Y0 <- filter(df, D == 0) %>% pull(Y)
```

--

```{r}
(dm_hat <- mean(Y1) - mean(Y0))
```


Legislators were 1.7 percentage points less likely to reply to an email if the sender was identified as DeShawn Jackson as compared to Jake Mueller. 

---

Note that again, the population that we're taking inference over is legislators--all of whom are included in our experiment. We're not assuming we're sampling from some other distribution. The only source of randomness is how treatment is assigned. 

---

There are ${4859 \choose 2428}$ different ways treatment could be assigned--this is too many to generate the whole matrix of permutations and get the *exact* sampling distribution. 

Instead, we'll simulate the sampling process many times to find the *approximate* sampling distribution of $\hat\tau_{DM}$ under the sharp null.

--

```{r}
# randomization inference function
my_ri <- function(df){
  ri_out <- df %>%
    mutate(newD = sample(D)) %>%
    group_by(newD) %>%
    summarize(mean = mean(Y)) %>%
    pivot_wider(names_from = newD, values_from = mean) %>%
    mutate(diff = `1` - `0`) %>%
    pull(diff)

  return(ri_out)
}
```

---

We can do this many times to find the distribution of $\hat\tau_{DM}$ under the sharp null.


```{r}
reps <- 1000

null_dist <- tibble(
  dm = replicate(n = reps,
                 my_ri(df))
)

null_dist
```

---

```{r, fig.height=4, fig.width = 5, fig.align = "center", echo=FALSE}

gg_bins <- null_dist %>% 
  count(bins = cut(dm, breaks = 50)) %>% 
  mutate(bin_min = as.numeric(gsub(".?(-?[0-9]+[.]+[0-9]+).*", "\\1", bins)),
         bin_max = as.numeric(gsub(".*,(-?[0-9]+[.]+[0-9]+)]$", "\\1", bins)),
         bin_mid = (bin_max - bin_min)/2 + bin_min,
         col = abs(bin_min) >= abs(dm_hat)) 


ggplot(gg_bins, aes(x = bin_mid, y = n)) +
  geom_col() +
  geom_vline(xintercept = 0, color = 'red')
```

--



```{r}
(pval <- mean(abs(null_dist) >= abs(dm_hat)))
```

---


```{r, fig.height=4, fig.width = 5, fig.align = "center", echo=FALSE}

ggplot(gg_bins, aes(x = bin_mid, y = n, fill = col)) +
  geom_col() +
  geom_vline(xintercept = 0, color = 'red') + 
  scale_fill_manual(values=c("grey35", "#619CFF")) +
  theme(legend.position = 'none')

```



```{r}
(pval <- mean(abs(null_dist) >= abs(dm_hat)))
```

---

The types of hypotheses we've considered are two-sided hypotheses: we look at effects in either direction from zero. 

--

$$
H_0: \tau_i = 0, \text{ for all } i \text{ in our pop.}
$$


$$
H_A: \tau_i \neq 0, \text{ for some } i \text{ in our pop.}
$$

---

We can also consider other alternative hypotheses. For example, the hypothesis that treatment effects are less than zero. This is called a one-sided hypothesis. 


--

$$
H_0: \tau_i = 0, \text{ for all } i \text{ in our pop.}
$$


$$
H_A: \tau_i < 0, \text{ for some } i \text{ in our pop.}
$$

---
The alternative hypothesis that we consider is a consequence of the social science theory we're trying to test. 

--

Here, we want to see if legislators are *less likely* to respond to a constituent named DeShawn Jackson, as compared to Jake Mueller. 

--

When we test a one-sided hypothesis, we want to check how likely we would be to observe statistics at least as large as the test statistic that we actually observe, in the direction of our hypothesis. 

---


```{r, fig.height=4, fig.width = 5, fig.align = "center", echo=FALSE}

gg_bins <- gg_bins %>% 
  mutate(col2 = bin_min <= dm_hat)

ggplot(gg_bins, aes(x = bin_mid, y = n)) +
  geom_col() +
  geom_vline(xintercept = 0, color = 'red') 

```



```{r}
(pval <- mean(null_dist <= dm_hat))


```


---


```{r, fig.height=4, fig.width = 5, fig.align = "center", echo=FALSE}

gg_bins <- gg_bins %>% 
  mutate(col2 = bin_mid <= dm_hat)

ggplot(gg_bins, aes(x = bin_mid, y = n, fill = col2)) +
  geom_col() +
  geom_vline(xintercept = 0, color = 'red') + 
  scale_fill_manual(values=c("grey35", "#619CFF")) +
  theme(legend.position = 'none')

```



```{r}
(pval <- mean(null_dist <= dm_hat))


```

---
class: tiny

## P-values

Suppose $\hat{\theta}$ is the general form for an estimate produced by our estimator, and $\hat{\theta}^*$ is the value we have actually observed. 

--

- A lower one-tailed p-value under the null hypothesis is 

$$
p = \textrm{P}\_0[\hat{\theta} \le \hat{\theta}^*]
$$

i.e., the probability *under the null distribution* that we would see an estimate of $\hat{\theta}$ that is less than or equal to what we saw from the data. 

--

- An upper one-tailed p-value under the null hypothesis is 

$$
p = \textrm{P}\_0[\hat{\theta} \ge \hat{\theta}^*]
$$

i.e., the probability *under the null distribution* that we would see an estimate of $\hat{\theta}$ that is greater than or equal to what we saw from the data. 


--
- A two-tailed p-value under the null hypothesis is 

$$
p = \textrm{P}\_0[|\hat{\theta}| \ge |\hat{\theta}^*|]
$$

i.e., the probability *under the null distribution* that we would see an estimate of $\hat{\theta}$ as or more extreme as what we saw from the data. 

